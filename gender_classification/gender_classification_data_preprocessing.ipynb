{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import spacy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note if you have train, test, validation data sets, scroll down to Client aggregations, and change load_data=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:\\\\Users\\\\grigor.vardanyan\\\\Desktop\\\\msdata\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(base + \"transactions.csv\")\n",
    "mcc = pd.read_csv(base + \"tr_mcc_codes.csv\",sep=\"\\t\")\n",
    "tr_types = pd.read_csv(base + \"tr_types.csv\")\n",
    "clients = pd.read_csv(base + \"gender_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(clients.gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3713, 0: 4687})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_1 = clients.loc[clients.gender == 1][\"customer_id\"].values\n",
    "clients_0 = clients.loc[clients.gender == 0][\"customer_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_1_treshold = int(len(clients_1) * 0.9)\n",
    "clients_1_train =  clients_1[:client_1_treshold]\n",
    "clients_1_test = clients_1[client_1_treshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_0_treshold = int(len(clients_0) * 0.9)\n",
    "clients_0_train =  clients_0[:client_0_treshold]\n",
    "clients_0_test = clients_0[client_0_treshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_train = np.concatenate((clients_0_train, clients_1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_test = np.concatenate((clients_0_test, clients_1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.drop([\"term_id\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transactions = transactions.loc[transactions[\"customer_id\"].isin(clients_train)]\n",
    "test_transactions = transactions.loc[transactions[\"customer_id\"].isin(clients_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions of unknown clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_transactions = transactions.loc[~transactions[\"customer_id\"].isin(clients[\"customer_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_unk = set(unknown_transactions[\"customer_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6600"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clients_unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature - index pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_unique = set(transactions[\"mcc_code\"].values)\n",
    "tr_type_unique = set(transactions[\"tr_type\"].values)\n",
    "union_features = mcc_unique.union(tr_type_unique).union(transactions[\"mcc_code\"]).union(transactions[\"tr_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_names = [\"count\",\"mean\",\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_id = {\"amount\":0}\n",
    "#Add mcc features\n",
    "for feature_name in union_features:\n",
    "    for agg_name in agg_names:\n",
    "        key = str(feature_name) + \"-\" + \"amount\" + \"-\" + agg_name  \n",
    "        feature_id[key] = len(feature_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_dict_gender.pkl\", \"wb+\") as file:\n",
    "    pickle.dump(feature_id, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    train_transactions = pd.read_csv(\"train_transactions.csv\")\n",
    "    val_transactions_df = pd.read_csv(\"validation_transactions.csv\")\n",
    "    \n",
    "    with open(\"features_dict_gender.pkl\", \"rb\") as file:\n",
    "        feature_id = pickle.load(file)\n",
    "else:\n",
    "    #Join with clients dataframe train and test dataframes\n",
    "    train_transactions = pd.merge(train_transactions, clients)\n",
    "    test_transactions = pd.merge(test_transactions, clients)\n",
    "    #Get unique clients\n",
    "    train_clients_set = set(train_transactions[\"customer_id\"].values)\n",
    "    train_clients_list = list(train_clients_set)\n",
    "    #Create validation\n",
    "    treshold = int(len(train_clients) * 0.9)\n",
    "    train_clients = train_clients_list[:treshold]\n",
    "    valid_clients = train_clients_list[treshold:]\n",
    "    #Split dataframe into train and validation\n",
    "    train_transactions_df = train_transactions.loc[train_transactions[\"customer_id\"].isin(train_clients)]\n",
    "    val_transactions_df = train_transactions.loc[train_transactions[\"customer_id\"].isin(valid_clients)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function iterates over per client transactions(client_transactions is padas grouped dataframe) and count aggreagations\n",
    "#to create sparse feature matrix\n",
    "def create_sparse_matrix(client_transactions, feature_id):\n",
    "    data = []\n",
    "    rows_id = []\n",
    "    columns_id = []\n",
    "    labels = []\n",
    "    \n",
    "    row_id = 0\n",
    "    \n",
    "    for client_id, client_purchase in tqdm(client_transactions,total=len(client_transactions)):\n",
    "        #Remove uneccesary columns\n",
    "        mcc_df = client_purchase.drop([\"customer_id\",\"tr_datetime\",\"tr_type\",\"gender\"],axis=1)\n",
    "        tr_type_df = client_purchase.drop([\"customer_id\",\"tr_datetime\",\"mcc_code\",\"gender\"],axis=1)\n",
    "        #Aggregate based on two categorical features\n",
    "        mcc_agg = mcc_df.groupby(\"mcc_code\").agg([\"count\",\"mean\",\"std\"]).fillna(0)\n",
    "        tr_type_agg = tr_type_df.groupby(\"tr_type\").agg([\"count\",\"mean\",\"std\"]).fillna(0)\n",
    "    \n",
    "        for amount in client_purchase.amount.values:\n",
    "            #Add amount \n",
    "            data.append(amount)   \n",
    "            rows_id.append(row_id)\n",
    "            columns_id.append(feature_id[\"amount\"])\n",
    "            labels.append(str(client_purchase.gender.values[0]))\n",
    "        \n",
    "            # Iterate ove mcc and add data\n",
    "            for mcc_index in list(mcc_agg.index):\n",
    "                mcc_row = mcc_agg.loc[mcc_index]\n",
    "                for agg_name in agg_names:\n",
    "                    amount_agg_val = mcc_row[\"amount\"][agg_name]\n",
    "                    key = str(mcc_index) + \"-\" + \"amount\" +  \"-\" + agg_name\n",
    "                \n",
    "                    #Add data\n",
    "                    data.append(amount_agg_val)\n",
    "                    rows_id.append(row_id)\n",
    "                    columns_id.append(feature_id[key])\n",
    "                \n",
    "            #Iterate over transaction type and add data\n",
    "            for tr_type_index in list(tr_type_agg.index):\n",
    "                tr_type_row = tr_type_agg.loc[tr_type_index]\n",
    "                for agg_name in agg_names:\n",
    "                    amount_agg_val = tr_type_row[\"amount\"][agg_name]\n",
    "                    key = str(tr_type_index) + \"-\" + \"amount\" + \"-\" + agg_name\n",
    "                \n",
    "                    #Add data\n",
    "                    data.append(amount_agg_val) \n",
    "                    rows_id.append(row_id)\n",
    "                    columns_id.append(feature_id[key]) \n",
    "        \n",
    "            row_id+=1\n",
    "    return rows_id, columns_id, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_groups = val_transactions_df.groupby(\"customer_id\")\n",
    "train_groups = train_transactions_df.groupby(\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_id_train, columns_id_train, data_train, labels_train = create_sparse_matrix(train_groups,feature_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 134/756 [21:07<3:35:17, 20.77s/it]"
     ]
    }
   ],
   "source": [
    "rows_id_val, columns_id_val, data_val, labels_val = create_sparse_matrix(validation_groups, feature_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_id_test, columns_id_test, data_test, labels_test = create_sparse_matrix(test_transactions, feature_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data into txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(data, file_name):\n",
    "    with open(file_name,\"w+\") as f:\n",
    "        iters = range(len(data) - 1)\n",
    "        for it in tqdm(iters,total=len(iters)):\n",
    "            writable = str(data[it]) + \",\"\n",
    "            f.write(str(writable))\n",
    "        f.write(str(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Train data\n",
    "save_txt(rows_id_train,\"train_rows.txt\")\n",
    "save_txt(columns_id_train,\"train_column.txt\")\n",
    "save_txt(data_train,\"train_data.txt\")\n",
    "save_txt(labels_train,\"train_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save valid data data\n",
    "save_txt(rows_id_t_val,\"valid_rows.txt\")\n",
    "save_txt(columns_id_val,\"valid_column.txt\")\n",
    "save_txt(data_val,\"valid_data.txt\")\n",
    "save_txt(labels_val,\"valid_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save test data data\n",
    "save_txt(rows_id_test,\"test_rows.txt\")\n",
    "save_txt(columns_id_test,\"test_column.txt\")\n",
    "save_txt(data_test,\"test_data.txt\")\n",
    "save_txt(labels_test,\"test_labels.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
